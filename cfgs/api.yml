# api config

qwen:
  base_url: https://dashscope.aliyuncs.com/compatible-mode/v1
  model: qwen2.5-72b-instruct # qwen-long, qwen-plus
  api_key: DASHSCOPE_API_KEY  # the os environment variable name
  batch_infer: True  # whether to use the batch inference
  concurrency_level: 2 # the concurrency level for api request

#deepseek:
#  base_url: https://api.deepseek.com/v1
#  model: deepseek-chat
#  api_key: DEEPSEEK_API_KEY  # the os environment variable name
#  batch_api: False  # whether to use the bacth api

deepseek:
  base_url: https://dashscope.aliyuncs.com/compatible-mode/v1
  model: deepseek-v3
  api_key: DASHSCOPE_API_KEY  # the os environment variable name, DEEPSEEK_API_KEY for official key from DeepSeek
  batch_infer: True  # whether to use the bacth api
  concurrency_level: 2 # the concurrency level for api request

gpt:
  base_url: https://fastapi.top/v1
#  base_url: https://api.chatgpt-3.vip/v1
  model: gpt-4o-mini # gpt-4o-mini, gpt-3.5-turbo(gpt-3.5-turbo-0125), gpt-3.5-turbo-instruct
  api_key: OPENAI_API_KEY  # the os environment variable name
  batch_infer: False  # whether to use the bacth api
  concurrency_level: 2 # the concurrency level for api request

# add more model api that are openai-compatible here